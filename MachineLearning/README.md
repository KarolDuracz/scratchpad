<b>Demo 1</b><br />
In this case: <br />
- Transfer learning is the same as the survival of the entire species, i.e. it is to serve the transfer of knowledge that will allow it not to die as a whole species. <br />
The main goal and strategy of development (evolution) should be to develop the ability to quickly find food, or to search optimally, i.e. one that takes the least amount of time. 
- This should be transferred in "global memory transfer". Because finding as much food as possible can be the goal (task) within which these objects will develop a strategy of searching 
for food and surviving as a whole species.<br />
- This is base code for explore more about RL and compare with this: https://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html
or this https://github.com/karpathy/reinforcejs/tree/master etc
- there is some errors  --> for example this "creatures" don't have this skills  which I wrote about above but I plan to deep dive into it in my free time <br /><br />
<i>NOTE: Transfer learning is similar to CUDA and parallel computing in my opinion. More "creatures" is equal to  more compute cores (CUDA etc)
But this world is 2d. This creature can move  ⬇️⬆️⬅️➡️ but in 3d world if I add simple optical part to creature which is random grid for example 3x3 or 10x10 size.  More pixels = more "range of view". And architecture of visual part is like CNN or mini transformer... sth like that.</i><br /><br />
This looks like this <br />

![dump](https://raw.githubusercontent.com/KarolDuracz/scratchpad/main/MachineLearning/rl_demo1_screenshot.png)
