Maybe useful tool - TODO
<br />
What if I've changed something in the transformers model so that it would read the page on an ongoing basis, or more precisely the documentation or repository on github, 
and based on the collected (observed) tokens it would learn something about it... that would be useful for analyzing the code.
<br />
Why manually search, clicked, scroll, read when the model can do some of this tedious work for you...
<br />
It should work like a search engine, only the model itself has to do it.
<br />
TODO - checkpint 12-09-2024 - 

<br />
Maybe it will be useful, maybe not. Today I would definitely need a model that understands repos, e.g. DirectX or WINAPI better than me.
<br />
Maybe at the end of 2025 i'd back to this... 

<br /><br />
Transformer can create a projection for each word (token). The model sees all combinations for a word. Human (I) there is no such large memory to understand so many combinations at the same time. IIn mind we can create visualisation like map or something, but to solve this problem, human can do only sequence word by word. If add more context (context length) than 1 token this is probably impossible for anyone to solve. But the transformer model can do it. And that's what's interesting about it.
