Maybe useful tool - TODO
<br />
What if I've changed something in the transformers model so that it would read the page on an ongoing basis, or more precisely the documentation or repository on github, 
and based on the collected (observed) tokens it would learn something about it... that would be useful for analyzing the code.
<br />
Why manually search, clicked, scroll, read when the model can do some of this tedious work for you...
<br />
It should work like a search engine, only the model itself has to do it.
<br />
TODO - checkpint 12-09-2024 - 

<br />
Maybe it will be useful, maybe not. Today I would definitely need a model that understands repos, e.g. DirectX or WINAPI better than me.
<br />
Maybe at the end of 2025 i'd back to this... 

<br /><br />
Transformer can create a projection for each word (token). The model sees all combinations for a word. Human (I) there is no such large memory to understand so many combinations at the same time. IIn mind we can create visualisation like map or something, but to solve this problem, human can do only sequence word by word. If add more context (context length) than 1 token this is probably impossible for anyone to solve. But the transformer model can do it. And that's what's interesting about it.
<br />
<br />
I have a book - "Uczenie maszynowe z u≈ºyciem Scikit-Learn, Keras i TensorFlow. Wydanie II" [Polish edition] -  Chapter 17, page 522  there is a small example that short-term memory in humans is weak. Maybe someone who trains these areas has better results but this small example shows that the average person cannot remember a sequence. <br />
40, 27, 25, 36, 81, 57, 10, 73, 19, 68 <br />
50, 48, 46, 44, 42, 40, 38, 36, 34, 32, 30, 28, 26, 24, 22, 20, 18, 16, 14 <br />
At first glance, it seems that the first string is easier to remember because it is shorter, but... the second is a sequence of numbers descending from 50 to 14 by 2. And It turns out to be easier to remember this PATTERN <br />

<br /> This small example show what common human can do.

<br />
But this is not repo about this. But maybe about dentures for brain for myself to get better job in daily task or ... any other interesting tasks. 

<br /><br />But what about deep vision and task to create picture from prompt and and the other way round? This is a different topic. Maybe there will be an opportunity to learn something about it from EurekaLabs... 
