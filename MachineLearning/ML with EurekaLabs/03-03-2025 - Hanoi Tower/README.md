<h2>TODO</h2>
This is probably for 2026. I have too much "tralala" in my head right now when I look at this. Another bla bla bla. But to be clarify. What progress they have made in the AI ​​field since 2011, from AlexNet, this is something amazing. Transformer in 2017. pytorch etc. A lot of people did a great job and the result is Chat GPT. Now these models are getting bigger and bigger, They even need to build a small nuclear power plant to power it :) And the idea of ​​creating an LLM, a model that is an engineer, that learns deeply about topics in the field of science, physics, chemistry, etc. And understands, can compress and understand different correlations between words, it's amazing. [Fireside Chat With Ilya Sutskever and Jensen Huang AI Today and Vision of the Future March 2023] https://youtu.be/I6qQinoY9WM?t=1697 I once watched this interview, and this fragment about where is the limit that the model really understands the text - Ilya presented it well from 28:17, where he talks about what deep understanding means in the case of, for example, a crime novel. Interestingly, the transformer architecture was the answer to this problem.
<br /><br />
But maybe there is another way...
<br /><br />
How the model can understand such visualizations, ask the right question about "what is the problem here" and finally how it can create such visualizations itself. Logical puzzles etc. Because when I look at the "thinking process" idea, people from AI field solve the next problem in line. And in fact, the model should have a deep understanding of not only what it sees when seeing the photo (reality like human's eyes), but also what the problem is, how to solve it, and in the next stages different visualizations and approaches.

![dump](https://github.com/KarolDuracz/scratchpad/blob/main/MachineLearning/ML%20with%20EurekaLabs/03-03-2025%20-%20Hanoi%20Tower/1005_08.gif?raw=true)

Wow. Wiki takes a mathematical approach, cool. https://en.wikipedia.org/wiki/Tower_of_Hanoi
