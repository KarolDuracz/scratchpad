<h2>to be continued</h2>
But technically it is a function that measures the error of calculations made by the network based on parameters. That's it
<br /><br />
This XOR problem etc here is about how to measure ERROR LOSS OF NETWORK PREDICTION > https://stanford.edu/~jlmcc/papers/PDP/Volume%201/Chap8_PDP86.pdf
<br /><br />
And this micrograd demo just shows WHAT A NETWORK DOES IF IT DOES NOT HAVE NON-LINEAR functions like Tanh, only linear layers https://github.com/EurekaLabsAI/micrograd . It's
simple but shows how NEURAL NETWORK works underhood with or without nonlinear functions. And this XOR problem is about this.
<br /><br />
But it's more complex because for example MNIST needs a nonlinear classifier. In turn, the transformer and text generation and using Positional Encoding,
Attention is a separate topic, which is a response to what recurrent networks did. It's damn complicated.
<br /><br />
Overall how a transformer, PE, Attention works is more complex than I thought... 
<br /><br />
That's all for now.
<hr>
I think this is already correct thinking and I'm on the right path. But this is a damn deep topic to analyze. How they changed RNN to transformer and why they gave PE and Attention. I know why, but not much.
<br /><br />
After all this nonsense WHAT I WROTE HERE I ended up here, on <b>"Learning Internal Representations by Error Propagation"</b> and what these people improved in the Perceptrons: An Introduction to Computational Geometry is a book written by Marvin Minsky and Seymour Papert in 1969. And this XOR problem. I think I'm finally on the right path. (...) Plans, plans, but this is the CORE of it all, that these networks find a solution based on measuring the prediction error and improving the parameters so that the loss function is as small as possible. I tried to jump over everything but now I know why I got lost, since I did not understand what Rumelhart, Hinton and Williams were really doing
<br /><br />
OK, I think it's ok now and I think correctly. Now I need to educate myself.
