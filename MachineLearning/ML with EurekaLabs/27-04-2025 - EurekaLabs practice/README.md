A few more things before I take a break from this topic...

<h2>I'm asking CHATGPT 4o : How modern models of LLM can "understand". Can analyze using some internal approaches whole repositories or documents and learn from it. How model have ability to find different way to analyze data.</h2>

https://chatgpt.com/share/680dedaa-bbe8-8000-83da-efdd20adc5ff
<br /><br />
This is probably the ABILITY that OPEN AI was trying to achieve in LLM, I think. And today I see it in 4o. That ability and level of reasoning. And in my learning path I have to get to that point where I start thinking about this problem - how can a model analyze and understand in this way.
<br /><br />
In other words. You give the model a whole repo, e.g. EDK2 Tianocore, and ask a deep question about boot flow to extract step by step important lines etc. instead of doing it manually.
<br /><br />
At one of the interviews I heard that OPEN AI has visions of the levels of this LLM. And initially, the model can work within a few minutes at the moment. But in some time it will be able to work in the perspective of hours, days, weeks (And the answer to this problem is this CACHE MEMORY maybe, because the context is not big enough...I don't know). Until achieving full autonomy in running the entire company and managing, for example, 1000 people. I don't know if this trend will continue, but based on what is being taught to current models and their ability to analyze documents, understand, analyze images. Probably yes.
<br /><br />
<hr>
Next. I've been looking for this video for some time. https://youtu.be/8AnV7xAvpLQ?t=469 [GTC 2015: Teaching Deep Neural Networks, Introducing DIGITS DevBox (part 6)] . This is Andrej's example of RNN from 10 years ago.
And that's maybe a way to approach building probably as an exercise in 2026 of this -> https://github.com/KarolDuracz/scratchpad/tree/main/3D%20board%20'11 based on this guide ->
https://www.tensorflow.org/text/tutorials/image_captioning?hl=en . And in this recording, as Andrej says at 8:24 "we see image, and this imge goes through to the neural network and neural network starts to sample words one a t the time to describe this image". I think I'm making this too complicated. That's why I wrote in /08-04-2025 - EurekaLabs practice - update for 25-03-2025 demo/ these words about "pipeline". btw. This is generally a good exercise and task for neural networks. Some time ago I did not appreciate this task of "signing images" but today I can see that LLM is based on this ability, only probably developers have developed it and there is no RNN anymore, only a transformer.

<hr>
Maybe I was thinking wrong about ML and network training -> https://github.com/KarolDuracz/scratchpad/tree/main/MachineLearning/ML%20with%20EurekaLabs/08-04-2025%20-%20EurekaLabs%20practice%20-%20update%20for%2025-03-2025%20demo - maybe "machine learning" is the ability to deeply analyze data as in this short question here https://chatgpt.com/share/680dedaa-bbe8-8000-83da-efdd20adc5ff

<br /><br />
But this will be a topic for consideration in the coming months. Because I still need to master data processing in order to train the model like that. But it's interesting :) ML is interesting.
<br /><br />
<b>Ok, I had to realize some things to know what to do. Understand it from a psychological perspective. Time to start delving into the details of implementation and code...</b>

